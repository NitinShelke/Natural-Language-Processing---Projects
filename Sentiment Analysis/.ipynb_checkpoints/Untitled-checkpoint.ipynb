{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amber-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import naive_bayes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sunrise-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from com_in_nitin_utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "played-berkeley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>awww bummer shoulda get david carr third day ;d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset ca n't update facebook texte ... might c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>followinq shud tha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>add tweetie new iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>crazy day school 10 hour straiiight watch hill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>tell burst laugh really loud thank make come sulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>spring break plain city ... snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>hollis death scene hurt severely watch film wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>file taxis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>need hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>make sure dm post link video lt;lol&amp;gt;so n't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>go bed goodnight everyone sweet dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>haha n't worry 'll get hang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target                                               text\n",
       "0        0    awww bummer shoulda get david carr third day ;d\n",
       "1        0  upset ca n't update facebook texte ... might c...\n",
       "2        0                    whole body feel itchy like fire\n",
       "3        4                                 followinq shud tha\n",
       "4        4                             add tweetie new iphone\n",
       "5        4  crazy day school 10 hour straiiight watch hill...\n",
       "6        4  tell burst laugh really loud thank make come sulk\n",
       "7        0                   spring break plain city ... snow\n",
       "8        0  hollis death scene hurt severely watch film wr...\n",
       "9        0                                         file taxis\n",
       "10       0                                           need hug\n",
       "11       4  make sure dm post link video lt;lol&gt;so n't ...\n",
       "12       4              go bed goodnight everyone sweet dream\n",
       "13       4                        haha n't worry 'll get hang"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=preprocessTrain(\"train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "entire-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvect=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "weighted-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['text']\n",
    "y=df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "olive-scout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvect.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lucky-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vector=tfidfvect.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "polyphonic-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "junior-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "explicit-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "still-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector=tfidfvect.transform(X_train)\n",
    "test_vector=tfidfvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "practical-soundtrack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_vector,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "brazilian-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adult-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "continent-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs=GridSearchCV(estimator=model,param_grid={},cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stainless-dollar",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-00fe7f235ae5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_vector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\envs\\myenvironment\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\myenvironment\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\myenvironment\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\myenvironment\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    805\u001b[0m                                                        **fit_and_score_kwargs)\n\u001b[0;32m    806\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcand_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m                                    (split_idx, (train, test)) in product(\n\u001b[0m\u001b[0;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                                    enumerate(cv.split(X, y, groups))))\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\myenvironment\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    328\u001b[0m                 (\"Cannot have number of splits n_splits={0} greater\"\n\u001b[0;32m    329\u001b[0m                  \" than the number of samples: n_samples={1}.\")\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of splits n_splits=10 greater than the number of samples: n_samples=9."
     ]
    }
   ],
   "source": [
    "gs.fit(train_vector,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "rotary-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "developed-valuation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-patch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-conditions",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-facial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vietnamese-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStopwords():\n",
    "    stopwords=[]\n",
    "    with open(\"data/stopwords.txt\") as f:\n",
    "        lines=f.read().splitlines()\n",
    "    for line in lines:\n",
    "        stopwords.append(line)\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "freelance-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessTrain(trainPath):\n",
    "    stopwords=getStopwords()\n",
    "   \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    pattern = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\\ \"\n",
    "    df = pd.DataFrame(columns=['target', 'text'])\n",
    "    \n",
    "    data=pd.read_json(trainPath)\n",
    "    \n",
    "    file=data['data']\n",
    "    lable=[]\n",
    "    text=[]\n",
    "    for line in file:\n",
    "        lable.append(line['lName'])\n",
    "        text.append(line['lData'])\n",
    "    \n",
    "    for line in text:\n",
    "        doc=nlp(line)\n",
    "        clean_text=[]\n",
    "        for i in doc:\n",
    "            clean=str(re.sub(pattern,'',str(i.lemma_).lower().strip()))\n",
    "            if clean not in stopwords:\n",
    "                if clean not in string.punctuation:\n",
    "                    clean_text.append(clean)\n",
    "        df = df.append({'text': clean_text}, ignore_index=True)\n",
    "    df['text'] = [\" \".join(value) for value in df['text'].values]\n",
    "    df['target']=lable\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "specialized-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=preprocessTrain(\"train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "variable-staff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>awww bummer shoulda get david carr third day ;d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset ca n't update facebook texte ... might c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>followinq shud tha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>add tweetie new iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>crazy day school 10 hour straiiight watch hill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>tell burst laugh really loud thank make come sulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>spring break plain city ... snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>hollis death scene hurt severely watch film wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>file taxis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>need hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>make sure dm post link video lt;lol&amp;gt;so n't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>go bed goodnight everyone sweet dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>haha n't worry 'll get hang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target                                               text\n",
       "0        0    awww bummer shoulda get david carr third day ;d\n",
       "1        0  upset ca n't update facebook texte ... might c...\n",
       "2        0                    whole body feel itchy like fire\n",
       "3        4                                 followinq shud tha\n",
       "4        4                             add tweetie new iphone\n",
       "5        4  crazy day school 10 hour straiiight watch hill...\n",
       "6        4  tell burst laugh really loud thank make come sulk\n",
       "7        0                   spring break plain city ... snow\n",
       "8        0  hollis death scene hurt severely watch film wr...\n",
       "9        0                                         file taxis\n",
       "10       0                                           need hug\n",
       "11       4  make sure dm post link video lt;lol&gt;so n't ...\n",
       "12       4              go bed goodnight everyone sweet dream\n",
       "13       4                        haha n't worry 'll get hang"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dependent-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=getStopwords()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "pattern = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\\ \"\n",
    "df = pd.DataFrame(columns=['target', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "champion-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_json(\"train.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "democratic-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=data['data']\n",
    "lable=[]\n",
    "text=[]\n",
    "for line in file:\n",
    "    lable.append(line['lName'])\n",
    "    text.append(line['lData'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "separated-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for line in text:\n",
    "    doc=nlp(line)\n",
    "    clean_text=[]\n",
    "    for i in doc:\n",
    "        clean=str(re.sub(pattern,'',str(i.lemma_).lower().strip()))\n",
    "        if clean not in stopwords:\n",
    "            if clean not in string.punctuation:\n",
    "                clean_text.append(clean)\n",
    "    df = df.append({'text': clean_text}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "casual-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['text'] = [\" \".join(value) for value in df['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "animated-engineer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>awww bummer shoulda get david carr third day ;d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>upset ca n't update facebook texte ... might c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>followinq shud tha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>add tweetie new iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>crazy day school 10 hour straiiight watch hill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tell burst laugh really loud thank make come sulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>spring break plain city ... snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>hollis death scene hurt severely watch film wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>file taxis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>need hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>make sure dm post link video lt;lol&amp;gt;so n't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>go bed goodnight everyone sweet dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>haha n't worry 'll get hang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0     NaN    awww bummer shoulda get david carr third day ;d\n",
       "1     NaN  upset ca n't update facebook texte ... might c...\n",
       "2     NaN                    whole body feel itchy like fire\n",
       "3     NaN                                 followinq shud tha\n",
       "4     NaN                             add tweetie new iphone\n",
       "5     NaN  crazy day school 10 hour straiiight watch hill...\n",
       "6     NaN  tell burst laugh really loud thank make come sulk\n",
       "7     NaN                   spring break plain city ... snow\n",
       "8     NaN  hollis death scene hurt severely watch film wr...\n",
       "9     NaN                                         file taxis\n",
       "10    NaN                                           need hug\n",
       "11    NaN  make sure dm post link video lt;lol&gt;so n't ...\n",
       "12    NaN              go bed goodnight everyone sweet dream\n",
       "13    NaN                        haha n't worry 'll get hang"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "structured-amazon",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-07352e7f1611>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclean_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclean_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "clean_df['text'] = [\" \".join(value) for value in clean_df.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "canadian-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data=[]\n",
    "for i in text:\n",
    "    doc=nlp(i)\n",
    "    for token in doc:\n",
    "        clean_text=[]\n",
    "        clean=re.sub(pattern,'',str(token.lemma_.lower()))\n",
    "        if clean not in string.punctuation:\n",
    "            if clean not in stopwords:\n",
    "                if clean !=' ':\n",
    "                    clean_text.append(clean)\n",
    "        clean_data.append(list(clean_text))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "original-market",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "indonesian-consideration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['awww'],\n",
       " ['bummer'],\n",
       " ['shoulda'],\n",
       " ['get'],\n",
       " ['david'],\n",
       " ['carr'],\n",
       " ['third'],\n",
       " ['day'],\n",
       " [';d'],\n",
       " ['upset'],\n",
       " ['ca'],\n",
       " [\"n't\"],\n",
       " ['update'],\n",
       " ['facebook'],\n",
       " ['texte'],\n",
       " ['...'],\n",
       " ['might'],\n",
       " ['cry'],\n",
       " ['result'],\n",
       " ['school'],\n",
       " ['today'],\n",
       " ['also'],\n",
       " ['blah'],\n",
       " ['whole'],\n",
       " ['body'],\n",
       " ['feel'],\n",
       " ['itchy'],\n",
       " ['like'],\n",
       " ['fire'],\n",
       " ['followinq'],\n",
       " ['shud'],\n",
       " ['tha'],\n",
       " ['add'],\n",
       " ['tweetie'],\n",
       " ['new'],\n",
       " ['iphone'],\n",
       " ['crazy'],\n",
       " ['day'],\n",
       " ['school'],\n",
       " ['10'],\n",
       " ['hour'],\n",
       " ['straiiight'],\n",
       " ['watch'],\n",
       " ['hill'],\n",
       " ['tell'],\n",
       " ['ha'],\n",
       " ['happy'],\n",
       " ['birthday'],\n",
       " ['jb'],\n",
       " ['tell'],\n",
       " ['burst'],\n",
       " ['laugh'],\n",
       " ['really'],\n",
       " ['loud'],\n",
       " ['thank'],\n",
       " ['make'],\n",
       " ['come'],\n",
       " ['sulk'],\n",
       " ['spring'],\n",
       " ['break'],\n",
       " ['plain'],\n",
       " ['city'],\n",
       " ['...'],\n",
       " ['snow'],\n",
       " ['hollis'],\n",
       " ['death'],\n",
       " ['scene'],\n",
       " ['hurt'],\n",
       " ['severely'],\n",
       " ['watch'],\n",
       " ['film'],\n",
       " ['wry'],\n",
       " ['director'],\n",
       " ['cut'],\n",
       " ['file'],\n",
       " ['taxis'],\n",
       " ['need'],\n",
       " ['hug'],\n",
       " ['make'],\n",
       " ['sure'],\n",
       " ['dm'],\n",
       " ['post'],\n",
       " ['link'],\n",
       " ['video'],\n",
       " ['lt;lol&gt;so'],\n",
       " [\"n't\"],\n",
       " ['miss'],\n",
       " ['well'],\n",
       " ['get'],\n",
       " ['permission'],\n",
       " ['blessing'],\n",
       " ['first'],\n",
       " ['go'],\n",
       " ['bed'],\n",
       " ['goodnight'],\n",
       " ['everyone'],\n",
       " ['sweet'],\n",
       " ['dream'],\n",
       " ['haha'],\n",
       " [\"n't\"],\n",
       " ['worry'],\n",
       " [\"'ll\"],\n",
       " ['get'],\n",
       " ['hang']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data=[i for i in clean_data if i!=[]]\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "premier-edward",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-lancaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-signature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-competition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-farmer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-botswana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-campus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-bradford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-cheese",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-arrow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-permit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-energy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-brief",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-funds",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-scotland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-campaign",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-workshop",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-weight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-connectivity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-insulin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
